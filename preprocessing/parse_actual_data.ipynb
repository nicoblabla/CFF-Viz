{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tools import save_to_json\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "all_csv = glob.glob('../data/actual_data/raw/*.csv')\n",
    "\n",
    "li = []\n",
    "for filename in all_csv[::-1]:\n",
    "    df = pd.read_csv(filename, sep=';', parse_dates=['Arrival time', 'Arrival forecast', 'Departure time', 'Departure forecast'])\n",
    "    df = df.dropna(axis=0, subset=[\"Arrival time\", \"Arrival forecast\"])\n",
    "    df['Stop name'] = df['Stop name'].str.slice(0,30)\n",
    "    currentDay = datetime.strptime(filename[-14:-4], '%d.%m.%Y')\n",
    "    df['currentDay'] = currentDay\n",
    "    li.append(df.sort_values(by=[\"Journey identifier\", \"Arrival time\"]))\n",
    "df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of operation</th>\n",
       "      <th>Journey identifier</th>\n",
       "      <th>Operator ID</th>\n",
       "      <th>Operator abbreviation</th>\n",
       "      <th>Operator name</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Linie</th>\n",
       "      <th>Line Text</th>\n",
       "      <th>Rotation ID</th>\n",
       "      <th>Transport ID</th>\n",
       "      <th>Additional run TF</th>\n",
       "      <th>Cancelled TF</th>\n",
       "      <th>OPUIC</th>\n",
       "      <th>Stop name</th>\n",
       "      <th>Arrival time</th>\n",
       "      <th>Arrival forecast</th>\n",
       "      <th>Arrival forecast status</th>\n",
       "      <th>Departure time</th>\n",
       "      <th>Departure forecast</th>\n",
       "      <th>Departure forecast status</th>\n",
       "      <th>Non-stopping pass TF</th>\n",
       "      <th>Arrival delay</th>\n",
       "      <th>Departure delay</th>\n",
       "      <th>Geopos</th>\n",
       "      <th>lod</th>\n",
       "      <th>currentDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.10.22</td>\n",
       "      <td>85:11:1007:001</td>\n",
       "      <td>85:11</td>\n",
       "      <td>SBB</td>\n",
       "      <td>Schweizerische Bundesbahnen SBB</td>\n",
       "      <td>Zug</td>\n",
       "      <td>1007</td>\n",
       "      <td>IC4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8503000</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>2022-10-19 06:23:00</td>\n",
       "      <td>2022-10-19 06:23:36</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378176674223226, 8.540212349099065</td>\n",
       "      <td>http://lod.opentransportdata.swiss/didok/8503000</td>\n",
       "      <td>2022-10-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of operation Journey identifier Operator ID Operator abbreviation  \\\n",
       "0         19.10.22     85:11:1007:001       85:11                   SBB   \n",
       "\n",
       "                     Operator name Product ID  Linie Line Text  Rotation ID  \\\n",
       "0  Schweizerische Bundesbahnen SBB        Zug   1007       IC4          NaN   \n",
       "\n",
       "  Transport ID  Additional run TF  Cancelled TF    OPUIC  Stop name  \\\n",
       "0           IC              False         False  8503000  Zürich HB   \n",
       "\n",
       "         Arrival time    Arrival forecast Arrival forecast status  \\\n",
       "0 2022-10-19 06:23:00 2022-10-19 06:23:36                    REAL   \n",
       "\n",
       "  Departure time Departure forecast Departure forecast status  \\\n",
       "0            NaT                NaT                       NaN   \n",
       "\n",
       "   Non-stopping pass TF  Arrival delay  Departure delay  \\\n",
       "0                 False          False            False   \n",
       "\n",
       "                                  Geopos  \\\n",
       "0  47.378176674223226, 8.540212349099065   \n",
       "\n",
       "                                                lod currentDay  \n",
       "0  http://lod.opentransportdata.swiss/didok/8503000 2022-10-19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train station position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_all_stops \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/raw/stops.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# Only take the stops that are also in the actual data. Remove the bus station and the duplicates.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_stops \u001b[39m=\u001b[39m df_all_stops[df_all_stops[\u001b[39m'\u001b[39m\u001b[39mstop_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(df_sorted[\u001b[39m'\u001b[39m\u001b[39mStop name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())]\n\u001b[1;32m      4\u001b[0m df_stops \u001b[39m=\u001b[39m df_stops\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstop_name\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m stops \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "df_all_stops = pd.read_csv('../data/raw/stops.csv', sep=',')\n",
    "# Only take the stops that are also in the actual data. Remove the bus station and the duplicates.\n",
    "df_stops = df_all_stops[df_all_stops['stop_name'].isin(df['Stop name'].unique())]\n",
    "df_stops = df_stops.drop_duplicates(subset=\"stop_name\")\n",
    "stops = {}\n",
    "for i, stop in df_stops.iterrows():\n",
    "    stops[stop['stop_name']] = {'lat': stop['stop_lat'], 'lng': stop['stop_lon']}\n",
    "save_to_json('../data/actual_data/clean/stops.json', stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retards par ligne\n",
    "\n",
    "- Pour chaque row\n",
    "  - Si le journey identifier est le même que le précédent\n",
    "    - Prendre la gare des deux row, et y associer le retard de la 2ème row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df, df.shift(-1).add_prefix('next_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayForLine:\n",
    "    stationA: str\n",
    "    stationB: str\n",
    "    nbTrain: int\n",
    "    nbDelayed: int\n",
    "    totalDelay: int\n",
    "    nbCancelled: int\n",
    "\n",
    "    def __init__(self, stations):\n",
    "        self.stationA = stations[0]\n",
    "        self.stationB = stations[1]\n",
    "        self.nbTrain = 0\n",
    "        self.nbDelayed = 0\n",
    "        self.totalDelay = 0\n",
    "        self.nbCancelled = 0\n",
    "\n",
    "    def add(self, is_delayed, delay, cancelled):\n",
    "        self.nbTrain += 1\n",
    "        self.nbDelayed += is_delayed\n",
    "        self.totalDelay += delay # TODO maybe only if is_delayed is True\n",
    "        self.nbCancelled += cancelled\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DelayForLine: \" + json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        if line not in delay_by_line:\n",
    "            delay_by_line[line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line[line].add(is_delayed, delay, cancelled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_line.json', delay_by_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay by Line by Week day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line_by_day = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        weekday = row['currentDay'].weekday()\n",
    "        if weekday not in delay_by_line_by_day:\n",
    "            delay_by_line_by_day[weekday] = {}\n",
    "        if line not in delay_by_line_by_day[weekday]:\n",
    "            delay_by_line_by_day[weekday][line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line_by_day[weekday][line].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_line_by_day.json', delay_by_line_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay by line by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line_by_hour = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        hour = row['Arrival forecast'].hour\n",
    "        if hour not in delay_by_line_by_hour:\n",
    "            delay_by_line_by_hour[hour] = {}\n",
    "        if line not in delay_by_line_by_hour[hour]:\n",
    "            delay_by_line_by_hour[hour][line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line_by_hour[hour][line].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_line_by_hour.json', delay_by_line_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retards par gare\n",
    "\n",
    "Pour chaque row\n",
    "Associer le retards à la gare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayForStation:\n",
    "    stationName: str\n",
    "    stationGeopos: str # TODO maybe uncessary since we have the station infos already ?\n",
    "    nbDelayed: int\n",
    "    nbTrain: int\n",
    "    totalDelay: int\n",
    "    nbCancelled: int\n",
    "\n",
    "    def __init__(self, stationName, stationGeopos):\n",
    "        self.stationName = stationName\n",
    "        self.stationGeopos = stationGeopos\n",
    "        self.nbTrain = 0\n",
    "        self.nbDelayed = 0\n",
    "        self.totalDelay = 0\n",
    "        self.nbCancelled = 0\n",
    "\n",
    "\n",
    "    def add(self, is_delayed, delay, cancelled):\n",
    "        self.nbTrain += 1\n",
    "        self.nbDelayed += is_delayed\n",
    "        self.totalDelay += delay # TODO maybe only if is_delayed is True\n",
    "        self.nbCancelled += cancelled\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DelayForLine: \" + json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    if stationName not in delay_by_station:\n",
    "        delay_by_station[stationName] = DelayForStation(stationName, stationGeopos)\n",
    "    delay_by_station[stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_station.json', delay_by_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retard par jour de la semaine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station_by_day = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    weekday = row['currentDay'].weekday()\n",
    "    if weekday not in delay_by_station_by_day:\n",
    "        delay_by_station_by_day[weekday] = {}\n",
    "    if stationName not in delay_by_station_by_day[weekday]:\n",
    "        delay_by_station_by_day[weekday][stationName] = DelayForStation(stationName, stationGeopos)\n",
    "    delay_by_station_by_day[weekday][stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_station_by_day.json', delay_by_station_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retard par heure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station_by_hour = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    hour = row['Arrival forecast'].hour\n",
    "    if hour not in delay_by_station_by_hour:\n",
    "        delay_by_station_by_hour[hour] = {}\n",
    "    if stationName not in delay_by_station_by_hour[hour]:\n",
    "        delay_by_station_by_hour[hour][stationName] = DelayForStation(stationName, stationGeopos)\n",
    "    delay_by_station_by_hour[hour][stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../data/actual_data/clean/delay_by_station_by_hour.json', delay_by_week)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
