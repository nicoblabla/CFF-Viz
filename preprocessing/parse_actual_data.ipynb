{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tools import save_to_json\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "all_csv = glob.glob('../data/actual_data/raw/*.csv') # TODO\n",
    "all_csv.sort()\n",
    "\n",
    "li = []\n",
    "for filename in all_csv:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, sep=';', parse_dates=['Arrival time', 'Arrival forecast', 'Departure time', 'Departure forecast'])\n",
    "    df = df.dropna(axis=0, subset=[\"Arrival time\", \"Arrival forecast\"])\n",
    "    df['Stop name'] = df['Stop name'].str.slice(0,30)\n",
    "    currentDay = datetime.strptime(filename[-14:-4], '%Y-%m-%d')\n",
    "    df['currentDay'] = currentDay\n",
    "    li.append(df.sort_values(by=[\"Journey identifier\", \"Arrival time\"]))\n",
    "df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train station position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_stops = pd.read_csv('../data/raw/stops.csv', sep=',')\n",
    "# Only take the stops that are also in the actual data. Remove the bus station and the duplicates.\n",
    "df_stops = df_all_stops[df_all_stops['stop_name'].isin(df['Stop name'].unique())]\n",
    "df_stops = df_stops.drop_duplicates(subset=\"stop_name\")\n",
    "stops = {}\n",
    "for i, stop in df_stops.iterrows():\n",
    "    stops[stop['stop_name']] = {'lat': stop['stop_lat'], 'lng': stop['stop_lon']}\n",
    "save_to_json('../web/data/stops.json', stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retards par ligne\n",
    "\n",
    "- Pour chaque row\n",
    "  - Si le journey identifier est le même que le précédent\n",
    "    - Prendre la gare des deux row, et y associer le retard de la 2ème row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df, df.shift(-1).add_prefix('next_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayForLine:\n",
    "    stationA: str\n",
    "    stationB: str\n",
    "    nbTrain: int\n",
    "    nbDelayed: int\n",
    "    totalDelay: int\n",
    "    nbCancelled: int\n",
    "\n",
    "    def __init__(self, stations):\n",
    "        self.stationA = stations[0]\n",
    "        self.stationB = stations[1]\n",
    "        self.nbTrain = 0\n",
    "        self.nbDelayed = 0\n",
    "        self.totalDelay = 0\n",
    "        self.nbCancelled = 0\n",
    "\n",
    "    def add(self, is_delayed, delay, cancelled):\n",
    "        self.nbTrain += 1\n",
    "        self.nbDelayed += is_delayed\n",
    "        self.totalDelay += delay # TODO maybe only if is_delayed is True\n",
    "        self.nbCancelled += cancelled\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DelayForLine: \" + json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_merged.loc[(df_merged['Day of operation'] == '2022-10-26') & (df_merged['Journey identifier'] == '85:11:1077:001')]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLinesWithNoTrains(delays):\n",
    "    return {k: v for k, v in delays.items() if v.nbTrain > 30}\n",
    "\n",
    "def removeLinesWithNoTrains2(delays):\n",
    "    #return {k: {v2 for k2, v2 in v.items() if v2.nbTrain > 30} for k, v in delays.items()}\n",
    "    return {day: {line: info for line, info in lines.items() if info.nbTrain > 30} for day, lines in delays.items()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        if line not in delay_by_line:\n",
    "            delay_by_line[line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line[line].add(is_delayed, delay, cancelled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../web/data/delay_by_line.json', removeLinesWithNoTrains(delay_by_line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay by Line by Week day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line_by_day = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        weekday = row['currentDay'].weekday()\n",
    "        if weekday not in delay_by_line_by_day:\n",
    "            delay_by_line_by_day[weekday] = {}\n",
    "        if line not in delay_by_line_by_day[weekday]:\n",
    "            delay_by_line_by_day[weekday][line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line_by_day[weekday][line].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delay_by_line_by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removeLinesWithNoTrains2(delay_by_line_by_day))\n",
    "save_to_json('../web/data/delay_by_line_by_day.json', removeLinesWithNoTrains2(delay_by_line_by_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay by line by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_line_by_hour = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    if row['Journey identifier'] == row['next_Journey identifier']:\n",
    "        is_delayed = row['Arrival delay']\n",
    "        delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "        depart_station = row['Stop name']\n",
    "        arrival_station = row['next_Stop name']\n",
    "        cancelled = row['Cancelled TF']\n",
    "        sorted_stations = sorted([depart_station, arrival_station])\n",
    "        line = '|'.join(sorted_stations)\n",
    "        hour = row['Arrival forecast'].hour\n",
    "        if hour not in delay_by_line_by_hour:\n",
    "            delay_by_line_by_hour[hour] = {}\n",
    "        if line not in delay_by_line_by_hour[hour]:\n",
    "            delay_by_line_by_hour[hour][line] = DelayForLine(sorted_stations)\n",
    "        delay_by_line_by_hour[hour][line].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../web/data/delay_by_line_by_hour.json', removeLinesWithNoTrains2(delay_by_line_by_hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retards par gare\n",
    "\n",
    "Pour chaque row\n",
    "Associer le retards à la gare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayForStation:\n",
    "    stationName: str\n",
    "    #stationGeopos: str # TODO maybe uncessary since we have the station infos already ?\n",
    "    nbDelayed: int\n",
    "    nbTrain: int\n",
    "    totalDelay: int\n",
    "    nbCancelled: int\n",
    "\n",
    "    def __init__(self, stationName):\n",
    "        self.stationName = stationName\n",
    "        #self.stationGeopos = stationGeopos\n",
    "        self.nbTrain = 0\n",
    "        self.nbDelayed = 0\n",
    "        self.totalDelay = 0\n",
    "        self.nbCancelled = 0\n",
    "\n",
    "\n",
    "    def add(self, is_delayed, delay, cancelled):\n",
    "        self.nbTrain += 1\n",
    "        self.nbDelayed += is_delayed\n",
    "        self.totalDelay += delay # TODO maybe only if is_delayed is True\n",
    "        self.nbCancelled += cancelled\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DelayForLine: \" + json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    #stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    if stationName not in delay_by_station:\n",
    "        delay_by_station[stationName] = DelayForStation(stationName)\n",
    "    delay_by_station[stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../web/data/delay_by_station.json', delay_by_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retard par jour de la semaine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station_by_day = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    #stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    weekday = row['currentDay'].weekday()\n",
    "    if weekday not in delay_by_station_by_day:\n",
    "        delay_by_station_by_day[weekday] = {}\n",
    "    if stationName not in delay_by_station_by_day[weekday]:\n",
    "        delay_by_station_by_day[weekday][stationName] = DelayForStation(stationName)\n",
    "    delay_by_station_by_day[weekday][stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../web/data/delay_by_station_by_day.json', delay_by_station_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retard par heure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_by_station_by_hour = {}\n",
    "\n",
    "for i, row in df_merged.iterrows():\n",
    "    is_delayed = row['Arrival delay']\n",
    "    delay = abs(row['Arrival forecast'] - row['Arrival time']).total_seconds()\n",
    "    stationName = row['Stop name']\n",
    "    #stationGeopos = row['Geopos']\n",
    "    cancelled = row['Cancelled TF']\n",
    "    hour = row['Arrival forecast'].hour\n",
    "    if hour not in delay_by_station_by_hour:\n",
    "        delay_by_station_by_hour[hour] = {}\n",
    "    if stationName not in delay_by_station_by_hour[hour]:\n",
    "        delay_by_station_by_hour[hour][stationName] = DelayForStation(stationName)\n",
    "    delay_by_station_by_hour[hour][stationName].add(is_delayed, delay, cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json('../web/data/delay_by_station_by_hour.json', delay_by_station_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
